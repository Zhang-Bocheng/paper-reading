# Video as the New Language for Real-World Decision Makin
[paper link](https://arxiv.org/pdf/2402.17139) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2024 | This paper discusses how video data can be applied to solve real-world problems and suggests ways to achieve this through techniques such as self-supervised learning and reinforcement learning.          |  Reinforcement Learning        |

## Methodology

### 1. Abstract
The authors argue that video generation has significant potential for real-world applications compared to language models. By drawing on language models, video generation can be a unified interface that assimilates knowledge from the Internet and represents a variety of tasks. In addition, video generation can be used as a planner, agent, computational engine and environment simulator to support areas such as robotics and autonomous driving. However, video generation still faces some challenges such as poor video quality and lack of diversity. The authors call on researchers in related fields to work together to overcome these challenges so that video generation can be more useful.

### 2. Method Description 

### 3. Key concepts
  
### 4. Methodological improvements

### 5. Issues addressed 

## Experiments
This article introduces the application of video generation models in different domains and discusses their challenges and solutions. Specifically, the article is divided into the following four parts:

The first part is ‘Introduction’, which briefly introduces the background and significance of video generative modelling.

The second part is ‘Task-Specific Specialisation’, which lists different types of conditional video generation tasks and explains how they can be used to solve different problems.

The third part is ‘Unified State-Action Space’, which discusses how to use video as a unified state-action space for different robot learning tasks.

![image](https://github.com/user-attachments/assets/1dc74a1e-00e0-4c33-84f0-a40d3d933033)

The fourth section, ‘Visual Simulators’, shows how the video generation model can be used to simulate different physical processes, such as gaming environments, robot control, and so on.

Finally, the article summarises the advantages and challenges of video generation models and suggests some possible solutions. Overall, this article provides a comprehensive and in-depth perspective on the application and development of video generative modelling.

![image](https://github.com/user-attachments/assets/0db98237-324a-4212-90b5-e40de8767c6f)

## Conclusion

### 1. Advantages of the Thesis
  1. The article describes in detail the strengths and weaknesses of existing video generative models and how challenges, such as data limitations, model heterogeneity, and illusions, can be addressed.
  
  2. In addition, the authors explore the promise of video generation models for possible future applications as autonomous agents, planners, environment simulators, and computational engines.

### 2. Innovative points
  1. The paper presents some new perspectives and approaches to address the challenges faced by video generation models, such as methods for generating arbitrary videos using image/text inputs, and combining techniques such as reinforcement learning to improve the quality and efficiency of video generation.
  
  2. In addition, the authors introduce some new application scenarios, such as video inference, search, planning, and reinforcement learning, which can help solve real-world problems.
 
### 3. Future Works
Future research should continue to explore how video generation models can be improved to better suit different tasks and scenarios. In addition, researchers can combine video generative models with other techniques, such as computer vision, natural language processing, and machine learning, to achieve a wider range of applications.  
