# Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering
[paper link](https://arxiv.org/pdf/2309.06358) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2024 |  This paper explores the issue of robustness in Natural Language Processing (NLP) and focuses on how the robustness of models can be improved by using generative models for data augmentation in question and answer tasks.          | Natural Language Processing (NLP)         |

## Methodology

### 1. Abstract
The authors use a two-step generative approach where context and Q&A pairs are first generated and then added to an existing dataset to augment the data. Experimental results show that using the generated dataset significantly improves the performance and robustness of the model in the presence of natural distributional bias. This research provides new ideas and methods in the field of natural language processing, which can help to solve the challenges in real-world applications.

### 2. Method Description 
The study used two main approaches to create an extended version of the SQuAD dataset: **context generation and question-answer generation**. Firstly, consistent and diverse contexts were generated by providing a question in the SQuAD dataset and allowing the language model to generate a paragraph. This process ensures that the generated text matches the informative close-up format of the SQuAD dataset and complements the information in the original dataset. The generated paragraphs were then converted into question-answer pairs using the T5 Q&A-based generation model. Finally, the quality of the dataset was further improved by filtering out question-answer pairs that did not meet the circular consistency criteria.

![image](https://github.com/user-attachments/assets/74ccbb5b-041a-4038-bbae-0885221dabba)

### 3. Methodological improvements
In this study, the researchers used GPT-3.5 (gpt-3.5-turbo) as a context generator to ensure that the generated texts were of high quality and diversity. In addition, they used a T5-based Q&A generation model to generate question-answer pairs and a rounding consistency criterion to filter low-quality data.

### 4. Issues addressed 
This study aims to address the limitation of the SQuAD dataset, which is its small size that makes it difficult to meet the needs of machine learning algorithms. By using context generation and question-answer generation methods, the researchers succeeded in creating an extended version of the SQuAD dataset that can better support the learning and training of machine learning algorithms.

## Experiments
This paper focuses on the effect of using generated data on the distributional robustness of a reading comprehension model with three comparative experiments:

The first experiment explores **the effect of generative data in improving the distributional robustness of the model** by training the model with a mixture of real and generated data. The results show that using only generated data improves the robustness of the model, but decreases the absolute performance. In contrast, using a mixture of real and generated data results in a better balance, improving robustness while maintaining high absolute performance.

![image](https://github.com/user-attachments/assets/26895bf3-8f60-49b7-86d9-14b75913b56f)

The second experiment was to **determine how much generated data is needed to achieve optimal results**. The authors compared the effects of training models using different ratios of real and generated data and found that the models performed best when the ratio of the two data sources was 50:50.

![image](https://github.com/user-attachments/assets/644bd3b4-80ff-417b-8922-d07b3bf002e3)

A third experiment was **conducted to explore the need to generate context and questions to improve the distributional robustness of the model**. The results show that generating only questions is not effective in improving the robustness of the model, while generating both context and questions significantly improves the performance of the model.

## Conclusion

### 1. Advantages of the Thesis
  1. This paper investigates how ‘in-the-wild’ generated data can be used to enhance the performance of reading comprehension models, and proposes a new training method.
  
  2. The authors use the GPT-3.5 model to generate the data and demonstrate the superiority of this approach in terms of test set and natural distributional bias by comparing it with traditional training methods.
  
  3. In addition, the paper explores the impact of the generated data on the natural distribution bias in NLP, providing new ideas to solve this problem.

### 2. Innovative points
  1. This paper proposes a novel data augmentation method that uses the GPT-3.5 model to generate data to complement the real dataset. This training method improves the generalisation ability of the model so that it can better adapt to the natural distributional bias.
  
  2. In addition, the article adopts a two-layer generation approach, whereby first generating the context and then generating the Q&A pairs, further improves the quality of the data.

### 3. Future Works
In future research, the authors plan to explore more comparative experiments, such as comparing the present method with other data enhancement methods and investigating how it can be applied to larger models. In addition, the authors plan to further explore the impact of generative data on other tasks in NLP and how generative data can be applied to a wider range of domains.  
