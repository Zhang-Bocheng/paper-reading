# Improving Medical Dialogue Generation With Abstract Meaning Representations
[paper link](https://arxiv.org/pdf/2309.10608) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2023 | This paper explores how Abstract Meaning Representation (AMR) can be used to improve the quality of medical dialogue generation.          |  Attention Model        |

## Methodology

### 1. Abstract
Traditional textual representations have certain limitations and cannot fully express the semantic information of the text, so this paper introduces a graphical AMR representation for constructing a graphical model that describes the relationship between linguistic components and medical entities. The model employs a dual-attention mechanism to combine textual and graphical knowledge for modelling, and achieves better results than existing benchmark models in experiments.

### 2. Method Description 
The framework proposed in this paper consists of two independent encoders that process the heterogeneous features of the input text and the parsed AMR map, respectively. Subsequently, the decoder pays attention to the dual features from the encoders based on a dual-attention mechanism to predict the response tokens in an autoregressive manner.

![image](https://github.com/user-attachments/assets/e89c5fe3-ea9c-4501-bba0-0e340e4b0332)

### 3. Methodological improvements
This study uses the traditional Transformer architecture as a sequence encoder and introduces Graph Transformer to encode AMR graphs.Graph Transformer enhances the overall encoding process by efficiently encoding structured information through the processing of node and relationship information.

### 4. Issues addressed 
The method aims to simulate a conditional probability distribution P (Y | X, G) to generate doctor-like responses to medical dialogues. By fusing sentence and graphical features, as well as a dual attention mechanism, the model is better able to capture contextual information and generate more accurate and natural responses.

## Experiments
This paper focuses on exploring the performance improvement of a language model by introducing Abstract Meaning Representation (AMR) in a medical dialogue generation task and comparing it with a variety of benchmark models. Specifically, the following comparison experiments are used in this paper:

  1. **Data preparation:** raw utterances are transformed into corresponding AMR graphs, and relevant concepts and relations are extracted by an AMR simplifier;

  2. **Benchmark model selection:** five commonly used language models such as BART, T5, GPT-2, DialoGPT and Term-BART were selected as benchmark models;

  3. **Evaluation metrics:** several metrics such as BLEU, ROUGE, Dist-1, Dist-2, Dist-3 and Dist-4 were used to assess the quality of model generation;

  4. **Experimental results:** the results show that the framework proposed in this paper outperforms the benchmark model in all evaluation metrics, especially in the reference metrics, indicating that the introduction of AMR can improve the knowledge capture ability of the model; meanwhile, significant improvement is also achieved in the un-referenced metrics, suggesting that the introduction of AMR also improves the diversity of generated texts;

  5. **Model Size Impact:** Although bigger models usually perform better, this paper finds that increasing model parameters does not always lead to better performance improvement;

  6. **Ablation Study:** further demonstrates the effect of introducing AMR and that it provides unique semantic information compared to other features;

  7. **Quality Analysis:** by comparing the dialogues generated by different models, it is found that the method in this paper is more effective in answering patients' questions and is more in line with practical needs.  

![image](https://github.com/user-attachments/assets/432f335f-f795-4cb8-bd7e-0f1a0e1cb516)

## Conclusion

### 1. Advantages of the Thesis
The framework exploits the structured and semantically rich representation of AMR graphs to better capture the complex semantic and contextual relationships in medical dialogues, thereby generating more accurate and natural medical dialogues. Experimental results show that the framework performs better than the baseline model and has strong potential to improve the quality of medical dialogues.

### 2. Innovative points
  1. The authors propose a novel framework that combines AMR graphs with text and fuses heterogeneous features using a dual-attention mechanism to achieve better dialogue generation.
  2. In addition, the framework employs a combination of sequence encoders and graph encoders, enabling the system to better understand the semantic and logical relationships in medical dialogues. 

### 3. Future Works
   1. It is possible to further explore how to use more medical knowledge and background information to improve the effectiveness of dialogue generation.
   2. And, it is also possible to consider how to extend the framework to other domains, such as law and finance.

These research directions are expected to provide more possibilities for applications in the field of natural language processing.  
 
