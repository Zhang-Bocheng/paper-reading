# Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers
[paper link](https://arxiv.org/pdf/2309.08532) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2024 |  This paper presents a new framework called EVOPROMPT for optimising cue messages in NLP tasks.         |  large-scale language model (LLM)        |

## Methodology

### 1. Abstract
The framework combines a large-scale language model (LLM) with an evolutionary algorithm that iteratively generates new cues and improves the entire population based on the performance of the development set. Experimental results show that EVOPROMPT significantly outperforms human-designed cues and existing automatic cue generation methods on multiple datasets. In addition, the study demonstrates that connecting LLM and evolutionary algorithms can create synergistic effects, which may inspire more research on combining LLM and traditional algorithms.

### 2. Method Description 
This thesis presents EVOPROMPT, an evolutionary algorithm (EA)-based automatic cue generation framework for automatic generation of textual cues. The framework consists of three main steps: **initial population, evolution and update**. 
<br>&emsp;In the initial population phase, the authors take the available manual prompts as the initial population and introduce some prompts generated by a pre-trained language model (LLM). 
<br>&emsp;In the evolution phase, the authors use the LLM as an evolutionary operator to generate new cues, which is achieved by selecting several parent cues in the current population and designing mutation and crossover operations based on specific types of EA. 
<br>&emsp;In the update phase, the authors evaluate the newly generated candidate cues and keep the better performing cues in the development set.

![image](https://github.com/user-attachments/assets/d9113b7a-529c-432c-aed0-48af21c792f5)

### 3. Methodological improvements
Unlike most existing automated cueing methods, EVOPROMPT avoids the problem of local optimal solutions due to random initialisation by using human knowledge as the initial population. In addition, the framework considers cross-platform multi-language support and different input types to accommodate various application scenarios.

### 4. Issues addressed 
The EVOPROMPT framework proposed in this thesis solves the problem of lack of human a priori knowledge in traditional automatic prompting methods, and is better able to generate high-quality prompts. At the same time, the framework has good scalability and applicability to multiple languages and input types.

## Experiments
This paper focuses on EVOPROMPT, an optimisation method based on genetic algorithms and differential evolutionary algorithms, and applies it to the generation of prompts in several natural language processing tasks. Specifically, the paper conducts the following comparison experiments:

1. EVOPROMPT achieves better results in a variety of tasks compared to manually written guidance and human-written prompts;
2. EVOPROMPT(GA) slightly outperforms EVOPROMPT(DE) on the sentiment categorisation dataset, but the opposite is true on the topic categorisation dataset;
3. EVOPROMPT(DE) performs better than EVOPROMPT(GA) in the text simplification task;
4. EVOPROMPT achieves significant performance gains in both the SUMMARIZATION and Simplify tasks;
5. EVOPROMPT(DE) performs better in the BBH task, achieving an average improvement of 3.5%;

![image](https://github.com/user-attachments/assets/c7dff068-610f-4e0d-bd93-9cc89afd64c5)

6. For the selection strategy in GA, higher scores are achieved using the roulette selection method;
7. For the design considerations in DE, it is valid to vary only the different parts and select the best cue as Prompt 3.

## Conclusion

### 1. Advantages of the Thesis
The paper proposes a new framework, EVOPROMPT, that combines LLMs with evolutionary algorithms for automatic optimisation of discrete cues. The method has the following advantages:

1. It does not require access to any parameter or gradient information, making it suitable for many LLMs that do not provide an API interface.

2. By connecting LLMs and evolutionary algorithms, a balance between exploration and exploitation can be achieved, leading to better results.

3. The generated cues are readable and can be applied to a wide range of natural language processing tasks.
 
### 2. Innovative points
  1. The connection between LLM's expertise in NLP and the evolutionary algorithm's superior performance in optimisation is exploited.
  
  2. The use of LLM as a guide for evolutionary algorithm-directed search to improve optimisation efficiency, while maintaining cue coherence and readability.
  
  3. By designing appropriate evolutionary algorithm directed search strategies, a balance between exploration and exploitation was achieved, leading to better results.
 
### 3. Future Works
  1. Exploring more types of evolutionary algorithms and applying them to other traditional algorithms such as Particle Swarm Optimisation (PSO), Ant Colony Optimisation (ACO), etc.
  
  2. Investigate how evolutionary algorithms can be combined with other optimisation techniques to further improve optimisation.
  
  3. For more complex tasks, how to design more refined evolutionary algorithms directed search strategies to achieve higher optimisation efficiency. 
