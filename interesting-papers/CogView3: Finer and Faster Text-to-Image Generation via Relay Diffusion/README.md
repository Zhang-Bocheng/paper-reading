# CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion
[paper link](https://arxiv.org/abs/2403.05121) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2024 | This paper presents an innovative text-to-image generation framework called CogView3, which employs relay diffusion techniques and super-resolution processing on top of low-resolution images to improve image detail and efficiency.          |  Diffusion Model        |

## Methodology

### 1. Abstract
Experimental results show that CogView3 performs better in human evaluation compared to the current state-of-the-art open-source text-to-image diffusion model, SDXL, and requires only about half of its inference time. In addition, the distillation version of CogView3 achieves comparable performance to SDXL using only one-tenth of SDXL's inference time.

### 2. Method Description 
The paper proposes a text-to-image generation model called CogView3, which is centred on a diffusion model-based architecture. CogView3 consists of two stages: **base and relay**. The base model is trained at 512Ã—512 resolution and the text comprehension of the model is improved by using a pre-trained T5-XXL encoder as a text encoder. The relay model is responsible for upgrading the low-resolution images generated by the base to high resolution and can be directly applied to higher resolution outputs.

![image](https://github.com/user-attachments/assets/d723ca4c-d587-41a0-b543-4457d590c46f)

### 3. Methodological improvements
To address the mismatch that exists between traditional diffusion models and user input information, CogView3 used an automated data collection process. 

  1. They use GPT-4V to automatically generate a series of questions for the images and answer them, and then use these questions and answers to construct new captions. This approach produces more detailed and comprehensive descriptions of the images, which improves the performance of the model.

  2. CogView3 introduces the concept of extended prompts to further enhance user input. Better results are achieved by using the language model to extend user prompts into more detailed descriptions while preserving the original intent.

  3. CogView3 employs a hybrid strategy for training the diffusion model, including incremental training and relay diffusion. This strategy significantly reduces the overall training cost and allows different stages of CogView3 to share the same model structure.
 
### 4. Issues addressed 
The main goal of CogView3 is to improve the performance of text-to-image generation models, especially in generating more detailed and descriptive images. By automating the data collection process, extending hints, and hybrid training strategies, CogView3 addresses the mismatch between traditional diffusion models and user input information, enabling higher quality image generation.

## Experiments
This paper focuses on several comparative experiments conducted by the authors using their own model CogView3 with two baseline models, SDXL and Stable Cascade, and the results are analysed and summarised by both machine evaluation and human evaluation.

For machine evaluation, the authors used three metrics: the Aesthetic Score, the Human Preference Score v2 and the ImageReward. By comparing the DrawBench and PartiPrompts datasets, as well as additional validation on the COCO-5k dataset, the authors found that CogView3 performs better on most of the metrics compared to SDXL and Stable Cascade, and in particular achieves a significant advantage on the Aesthetic Score and Human Preference Score. In addition, the authors conducted a further compression experiment on cogView3, demonstrating its ability to produce better image quality at a lower cost.

![image](https://github.com/user-attachments/assets/a64091e6-b0e7-414e-a52c-6adf59cc6596)

In terms of human evaluation, the authors invited several annotators to compare and evaluate the generated results of CogView3, SDXL and Stable Cascade. They were asked to provide a win, lose or draw judgement on the generated results, as well as to evaluate their adherence to the cue statements and their aesthetics. By comparing the DrawBench dataset, the authors found that CogView3 outperforms SDXL and Stable Cascade in terms of adherence to cue statements and aesthetics.Additionally, the authors conducted a further compression experiment with cogView3, demonstrating that it is able to compress the generated results to a much higher effect.

![image](https://github.com/user-attachments/assets/8ed6a11c-bb66-42ac-818f-41864273d250)

## Conclusion

### 1. Advantages of the Thesis
  1. The paper presents a new text-to-image generation model, CogView3, which uses two modules, reliable sampler and progressive sampler, to improve generation quality and efficiency.

  2. CogView3 is the first diffusion process-based image generation model that uses a reliable sampler and is able to significantly reduce inference time while maintaining high quality.

  3. The paper also proposes a new framework called Relay Diffusion that can combine multiple low-resolution diffusion processes into a single high-resolution diffusion process, which further improves the generation quality.

### 2. Innovative points
  1. The concepts of reliable sampler and progressive sampler are proposed, allowing CogView3 to significantly reduce inference time while maintaining high quality.

  2. The use of the Relay Diffusion framework to combine multiple low-resolution diffusion processes into a single high-resolution diffusion process further improves the generation quality.

  3. Improvements to the model using data reformulation and cue expansion resulted in better instruction comprehension and task completion.

### 3. Future Works
  1. Further exploration can be done to optimise the parameter settings and training strategy of CogView3 for higher generation quality and faster inference.

  2. One can try to combine CogView3 with other techniques such as autoregressive modelling or reinforcement learning for more complex tasks.

  3. CogView3 can be considered for other applications such as video generation or speech synthesis to extend its range of applications.   
