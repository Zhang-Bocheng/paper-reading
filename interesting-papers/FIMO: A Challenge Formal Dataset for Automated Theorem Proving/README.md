# FIMO: A Challenge Formal Dataset for Automated Theorem Proving
[paper link](https://arxiv.org/pdf/2309.04295) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2023 | This paper presents a dataset called FIMO that contains formal mathematical problem statements from the International Mathematical Olympiad (IMO).          |  Large Language Models (LLMs)        |

## Methodology

### 1. Abstract
The dataset is intended to facilitate the study of automated theorem proving and is currently customised for the Lean formal language. The dataset contains 149 formal problem statements along with their corresponding informal descriptions and LATEX-based informal proofs. The authors have found, through initial experiments using GPT-4, that there are limitations in the current approach and that there is a long way to go before satisfactory IMO-level automated theorem proving results are achieved. The dataset has been published on GitHub and can be used under the terms of the Apache licence.

### 2. Method Description 
The paper proposes an approach called ‘Auto-Formalization’, which aims to convert informal mathematical problems into formal statements and to automate the process using the capabilities of Large Language Models (LLMs). Specifically, they use two phases: **optical character recognition (OCR) and automated proofs (auto-formalisation)**. In the first stage, they converted PDF files from the International Mathematical Olympiad (IMO) shortlist into LaTeX code. Then, in the second phase, they used the GPT-4 model to automatically derive formal representations of mathematical problems based on a small number of examples.

![image](https://github.com/user-attachments/assets/a4c64888-b37e-45f9-a7ed-bb1ae32d9f95)

### 3. Methodological improvements
The Auto-Formalisation approach significantly improves the efficiency and reduces the occurrence of human errors compared to the traditional manual conversion approach. In addition, by introducing a feedback mechanism, the method is able to continuously optimise the performance of the model, thus increasing the percentage of successful transformations.

### 4. Issues addressed 
This research addresses an important challenge in mathematics - how to convert informal mathematical problems into formal statements. This has important implications for applications such as automated proofs and machine learning. By proposing the ‘Auto-Formalization’ method, the authors provide an effective solution to this challenge.

## Experiments
This paper focuses on the use of pre-trained language models (LLMs) in the field of automated theorem proving, and compares and analyses these approaches through a series of experiments. Specifically, the paper compares existing LLMs with data-based automated theorem proving methods, and proposes a new approach that uses human-provided informal proofs to guide LLMs in generating formal proofs. In addition, this paper provides a detailed error analysis and reports results for this new method.

First, the paper compares existing LLMs with two common data-based automated theorem proving methods. These two methods are those that use only formal data for model fine-tuning and reasoning (e.g., PACT and Thor), and those that use both formal and informal data for pre-training and reasoning (e.g., GPT-f and DSP). Experimental results show that methods using informal data perform better in terms of performance as they are better able to capture the essential features of the problem and provide more contextual information.

Second, this paper proposes a new approach that uses human-provided informal proofs to guide LLM in generating formal proofs. The method is divided into two stages: **obtaining informal proofs and generating formal proofs**. In the first stage, it can automatically generate informal proofs by providing human-written informal proofs or using a pre-trained language model. In the second phase, we use informal proofs as hints to guide LLMs to generate formal proofs. Experimental results show that this approach is able to achieve good results in miniF2F benchmark tests without using complex search algorithms or further fine-tuning of the LLM.

Finally, the paper also analyses the limitations of using LLM for automated theorem proving. The experimental results show that the informal proofs generated by LLM are in most cases mathematically incorrect, and thus may mislead LLM to generate formal proofs. In addition, the experimental results also show that although the method of using informal proofs achieves better results in miniF2F benchmarking, there may still be some difficulties in practical applications, such as problems that require more advanced mathematical reasoning skills to solve. 

![image](https://github.com/user-attachments/assets/e50870e9-3f29-4c89-8459-8172e276e570)

## Conclusion

### 1. Advantages of the Thesis
  1. A new dataset of mathematical problems is presented: the FIMO, which contains formal statements from the International Mathematical Olympiad (IMO) as well as informal natural language proofs.
  
  2. The informal mathematical language is converted into a formal language such as Lean by automatic translation and human checks are used to ensure accuracy and consistency.
  
  3. The evaluation of the GPT-4 model on the FIMO dataset reveals the limitations of current large-scale language models in solving IMO-level mathematical problems.
  
  4. The findings highlight the enduring challenge of achieving automated theorem proving and point to the importance of continued innovation and research to bridge the gap between human expertise and machine capabilities.

### 2. Innovative points
  1. Utilising a combination of automatic generation and feedback improves the effectiveness of the automated translation process.
  
  2. Incorporates natural language proofs into the dataset, increasing the resources available to neural provers.
  
  3. Provides insight into future directions for improvement by evaluating the capabilities of existing methods.

### 3. Future Works
  1. Further improve the accuracy of automatic translation to better capture mathematical ideas in informal language.
  
  2. Explore ways to combine natural language proofs with other types of data to enhance the capabilities of neural provers.
  
  3. Develop more powerful algorithms and techniques to solve automated theorem proving problems at the IMO level. 
