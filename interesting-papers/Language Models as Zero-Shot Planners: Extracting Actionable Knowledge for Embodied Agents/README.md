# Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents
[paper link](https://arxiv.org/pdf/2201.07207) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2022 |This paper explores how pre-trained language models (LLMs) can be utilized to learn about the world and applied to interactive environments.          |  LLMs         |

## Methodology

### 1. Abstract
   The authors propose a methodology that breaks down the task of natural language expression into executable steps, taking into account existing presentations and semantic translations to ensure the feasibility of the program. Experimental results show that the approach significantly improves executability over the baseline. In addition, human evaluation revealed a trade-off: a balance between executability and correctness. 
   
   ![image](https://github.com/user-attachments/assets/fd34f9b1-34fc-4b39-8eef-7d76e81d94f0)

### 2. Method Description 
  The paper presents an approach based on pre-trained language models to extract executable knowledge to support robots' task completion in open worlds. They used the VirtualHome environment as a research object and evaluated it. Their approach consists of three main components: **Semantic Translation, Autoregressive Trajectory Correction, and Dynamic Example Selection**. These components are designed to improve the executability and correctness of programs generated by the language model.
  
  ![image](https://github.com/user-attachments/assets/967341a1-b8ac-4ee6-b731-d96217ea50b9)

### 3. Methodological improvements
  1.First, the paper mentions that there are some problems with direct input of natural language text into a pre-trained language model when generating action plans, such as the inability to translate into executable actions, the use of unrecognizable objects or words, etc. Therefore, they realized semantic translation of natural language text by using a pre-trained BERT-style language model to calculate the semantic distance between each acceptable environmental action and the predicted action.

  2. Second, in order to correct possible errors in action sequences, the paper proposes an autoregressive trajectory correction method. This method, after generating a single action, adjusts subsequent action sequences according to whether the action is acceptable and whether it is feasible in the environment. If the model generates an action that is not acceptable to the robot or cannot be executed, the action is replaced, thus avoiding the generation of further errors.

  3. Finally, the paper proposes a dynamic example selection method for providing weakly supervised signals. This method selects the most similar task and its corresponding example plan when querying the task in order to better guide the model in generating the correct sequence of actions.
     
### 4. Issues addressed 
  The method solves the problem of converting natural language text to executable action sequences while improving the executability and correctness of the generated action sequences. This helps robots to perform various tasks in the open world, such as controlling home appliances, cleaning rooms, etc. Moreover, the method can be extended to other domains such as self-driving cars, medical diagnostics, etc.

  ![image](https://github.com/user-attachments/assets/232f44f9-56e0-46f4-a13c-3007c26de244)

## Experiments
  This paper focuses on the performance of language models in higher-order tasks and explores how language models can be applied to physical environments. The authors conducted the following three comparative experiments:

**Correctness evaluation for higher-order tasks**: the authors used a representative generalized language model to generate action plans and invited human experts to evaluate these plans. The results show that when the language models are large enough and have no syntactic constraints, they can generate highly realistic action plans, even surpassing those written by humans. However, the generation results of some smaller language models (e.g., GPT-2) show that they often omit common-sense actions or simply restate given tasks, resulting in incomplete generated plans.

**Executability assessment of action plans**: the authors tested the generated action plans in a virtual home environment to assess their executability. It was found that plans generated by language models are usually not executable, especially for smaller language models. These non-executable plans usually ignore the query task and repeat the given example, which leads to low semantic similarity and executability.

**Evaluation of the effectiveness of the translation method**: The authors propose a translation method that improves the executability of plans by converting action plans generated by the language model into textual outputs that strictly follow the program syntax. The results show that the method significantly improves the executability of the generated plans and also has a higher semantic similarity since the translated plans are closer to those written by human experts. However, the human experts found these plans to be less correct than the original plans, mainly because the translation method did not map complex instructions well to simplified acceptable operations, and because certain necessary actions or objects were not implemented, leading to premature termination of the plans.


![image](https://github.com/user-attachments/assets/38e7beab-6033-458e-abd9-4dc37115e755)

## Conclusion

### 1. Advantages of the Thesis
   This paper proposes a method based on pre-trained language models to extract executable action plans, and experimentally verify the effectiveness and feasibility of the method. Specifically, the authors first define three components: **action translation, environment adaptation, and action sequence transformation**, and investigate and optimize them separately. Second, the authors use a virtual home dataset to evaluate the effectiveness of their method and compare it with other baseline methods. 
   
### 2. Innovative points
  1. **Based on a pre-trained language model**: using a pre-trained language model as a basis, the semantic information and contextual relationships in human activities can be better captured, thus improving the quality and accuracy of the action plans.

  2. **Components are well-designed**: the authors combine the three components of action translation, environment adaptation and action sequence transformation to form a complete action planning process that can effectively solve the goal-driven decision-making problem.

  3. **Significant experimental results**: the superiority of the method in terms of executability and LCS is demonstrated through comparative experiments with existing methods, and the ability of the pre-trained language model in generating executable programs is also demonstrated.

### 3. Future Works
Due to the lack of support from low-level control modules, it is not possible to achieve a true ground grid of sensor motion behaviors. In addition, the method is also unable to take into account important factors such as environmental context and feedback, thus further research and improvement is needed. Future work can be carried out in the following areas:

  1. Explore in depth the application scenarios and scope of motion planning to better meet practical needs.

  2. Investigate how to combine low-level control modules to achieve more complex tasks and behaviors.

  3. Consider more environmental factors and contextual information to improve the accuracy and reliability of action planning.
     
