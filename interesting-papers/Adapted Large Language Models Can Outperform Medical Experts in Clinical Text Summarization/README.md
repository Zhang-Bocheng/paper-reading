# Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
[paper link](https://arxiv.org/pdf/2309.07430) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2024 | The aim of this study was to investigate the effectiveness of large-scale language modelling (LLM) in clinical text summarisation.          | LLMs         |

## Methodology

### 1. Abstract
Eight LLMs were adapted through an adaptation approach and applied to four different clinical summarisation tasks: **radiology reports, patient questions, episode notes and doctor-patient dialogues**. The results of the experiment showed trade-offs between the different models and adaptation methods under several NLP metrics. In addition, a clinical readership study with 10 physicians revealed that summaries generated by the optimally adapted LLM had advantages over expert-generated summaries in terms of completeness, correctness, and conciseness for the former. 

However, the study also revealed challenges faced by LLMs and medical experts, including the potential for errors to lead to medical harm and different types of information fabrication. Overall, this study demonstrates that LLMs can outperform medical experts in multiple tasks, which opens up the possibility of integrating LLMs into clinical workflows, thereby reducing documentation burdens and allowing healthcare professionals to focus more on patient care.

### 2. Method Description 
This paper proposes the use of pre-trained LLMs for clinical text summarisation tasks. The authors use two types of LLMs: **sequence-to-sequence (seq2seq) models and autoregressive models**, and apply them to six different clinical text summarisation tasks. Of these, the seq2seq model maps the input text to the generated output via an encoder-decoder architecture, while the autoregressive model uses only the decoder, generating tokens one by one and capturing contextual information. The authors also introduce two adaptation methods: improvised seat learning (ICL) and quantified low-rank adjustment (QLoRA) to improve the performance of the models in specific domains.

![image](https://github.com/user-attachments/assets/921d592e-a6e5-4ad2-b276-1d87ef1badfc)

### 3. Methodological improvements
The methodological improvement of this paper lies in the introduction of two adaptation methods, ICL and QLoRA, to further improve the performance of the model in specific domains. Also, the authors consider a variety of open-source LLM models, including T5, FLAN-T5, LLAMA, etc., as well as some commercial models such as GPT-3.5 and GPT-4.

![image](https://github.com/user-attachments/assets/d2ac9b19-0942-4164-b3fb-4e79b47b8a4c)

### 4. Issues addressed 
This paper addresses the problem of how to use pre-trained large language models for clinical text summarisation tasks. By applying and comparing several different types of LLM models, the authors demonstrate the effectiveness of these models for the clinical text summarisation task and provide two effective adaptations to further improve the performance of the models. This approach could provide faster, accurate and reliable natural language processing solutions for the healthcare domain.

## Experiments
This paper focuses on the experimental design and analysis of results for a text summarisation task targeting the medical domain. Specifically, the authors conducted experiments in both quantitative evaluation and clinical readership studies, and provide a detailed description of the parameter settings, data processing methods, and NLP metrics used during the experiments.

![image](https://github.com/user-attachments/assets/b33becb6-902f-4be2-84bd-65da6e8238a4)

For quantitative evaluation, the authors used four metrics, BLEU, ROUGE-L, BERTScore and MEDCON, to assess the quality of the generated abstracts. These metrics are calculated based on the similarity between the reference text and the generated text. Among them, BLEU and ROUGE-L are commonly used metrics based on n-gram sequences, while BERTScore utilises a pre-trained language model for semantic similarity calculation. MEDCON is a metric used to measure the consistency of medical concepts. Ultimately, the authors arrived at the best model and method by comparing different models and tasks.

For the clinical readership study, the authors invited five radiologists and five internal medicine residents to evaluate the generated abstracts. The evaluation criteria included completeness, correctness, and conciseness. Using statistical methods such as the Wilcoxon signed-rank test and Bonferroni correction, the authors derived scores and statistical significance for each metric. In addition, the authors provided space for readers' comments for qualitative analyses.

Finally, the authors also conducted a safety analysis to link summary errors to medical harm. Using a multiple-choice format, the authors asked readers about their ability to make choices and judgements about situations where harm might be present. By statistically analysing samples where there were discrepancies, the authors derived the probability and degree of possible harm. 

![image](https://github.com/user-attachments/assets/1ce5af22-0b12-4cbe-bede-d01b4854191e)

## Conclusion

### 1. Advantages of the Thesis
  1. This study evaluates the performance of different adaptation strategies (i.e., domain-specific fine-tuning and task-specific fine-tuning) as well as different models (both open-source and proprietary) in clinical text abstract generation.
  
  2. By comparing with medical experts, it was found that abstracts generated using pre-trained language models are more complete, correct and concise, and may generate fewer errors than medical experts.
  
  3. For safety analyses, it was shown that abstracts generated using pre-trained language models may result in fewer potential harms.

### 2. Innovative points
  1. Various quantitative metrics were used in the study to measure the quality of the abstracts, such as BLEU, BERTScore and MEDCON, which can help to better understand the performance of the models.
  
  2. For the safety analysis, the authors considered not only whether the summaries generated by the model were accurate, but also whether they could lead to potential harm.

### 3. Future Works
  1. This study only covered some of the clinical document types, and future research could be expanded to include more document types and lengths.
  
  2. The adaptation of LLM to specific clinical areas or physician preferences could be further explored to improve the quality of abstracts.
  
  3. Considering data privacy issues, there is a need to ensure that the data used did not reveal any sensitive information. 
