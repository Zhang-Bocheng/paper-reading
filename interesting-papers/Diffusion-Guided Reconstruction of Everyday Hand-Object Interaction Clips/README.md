# Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips
[paper link](https://arxiv.org/pdf/2309.05663) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2023 | This paper describes a method for reconstructing hand-object interactions from short videos.          |  Neural Networks        |

## Methodology

### 1. Abstract
The authors use neural networks and data-driven prior knowledge to improve the accuracy of 3D inference, and learn diffusion networks to model the conditional distribution of object rendering to guide scene reconstruction. Experimental results show that the method achieves significant improvements on six different categories of selfie videos and can be used to reconstruct hand-object interactions from arbitrary clips from websites such as YouTube.

### 2. Method Description 
This thesis presents a monocular video-based reconstruction method for hand-object interaction. Firstly, a time-persistent implicit field is predicted by a multilayer perceptron to represent the object, and a parametric model MANO is used to represent the hand. They are then combined into a scene that can be reprojected back into image space. Next, the object and the hand are rendered using volume rendering and mesh rendering, respectively, and fused together to obtain geometric cues. Finally, the two masks are fused together by means of soft blending to compute the reconstruction loss and optimise the HOI representation in the whole sequence.

![image](https://github.com/user-attachments/assets/7d8952fd-9baf-4958-9055-249d4804ed1f)

### 3. Methodological improvements
  1. The method mainly improves the traditional HOI reconstruction method by introducing a data-driven prior for capturing the probability distribution of common object geometries under category and hand information.
  
  2. This prior is learnt through a diffusion model that asymptotically transfers from noise to real signals. During the training process, a large-scale labelled dataset is used to train the diffusion model to better capture the probability distribution of object geometries.
  
  3. In addition, the Score Distillation Sampling (SDS) technique is used in the inference phase to guide the optimisation process of the HOI representation by using the output of the diffusion model as a discriminator, which makes the recovered scene more consistent with the a priori conditions.

### 4. Issues addressed 
This method solves the problem of reconstructing human hand-object interaction in monocular video. While traditional methods usually require object templates to define object poses, the method does not require object templates and is therefore easier to apply to a variety of real-world situations. Also, by introducing a data-driven prior, the method can estimate the object geometry more accurately, thus improving the realism and believability of the interaction scene.

## Experiments
This paper focuses on the DiffHOI method proposed by the authors and verifies its performance and advantages through several comparative experiments. Specifically, the following four comparative experiments are conducted in this paper:

**Data-driven a priori analysis experiment**: this experiment analyses the impact of data-driven a priori on model reconstruction by visualising different object shapes and hand-object relationships generated by the model.

![image](https://github.com/user-attachments/assets/d0d978b5-6079-414d-adc2-f5e19968886e)

**Comparative reconstruction experiment**: this experiment compares DiffHOI with two template free-radical methods (HHOR and iHOI), and demonstrates that DiffHOI performs the best in most sequences by calculating metrics such as object reconstruction error and hand-object relation error under different categories.

![image](https://github.com/user-attachments/assets/e132b0d5-9fbb-400c-b6f9-dac13832f7c1)

**Prior contribution analysis experiment**: this experiment analyses the role of the prior on object reconstruction and hand-object relations by comparing diffusion models trained using only textual cues or hand-rendered images as conditions.

![image](https://github.com/user-attachments/assets/0ce344e8-4ecf-4337-a9ff-5b61cce6aae6)

**Model robustness experiment**: this experiment analyses the robustness of the model to initial hand pose errors by comparing it to a model using predicted hand poses instead of real hand poses.

![image](https://github.com/user-attachments/assets/5b70286a-54f0-4009-a355-6167f3894a56)

## Conclusion

### 1. Advantages of the Thesis
  1. This paper presents a new method to reconstruct hand-object interactions in everyday videos that accurately infers the shape of an object and its relative transformation with respect to the hand.
 
  2. Compared to previous methods, the method is more effective in dealing with unknown objects and can handle a small range of hand-object motions over a short period of time.
  
  3. In addition, the method incorporates data-driven and geometry-driven techniques to improve accuracy by learning a 2D diffusion network to guide the optimisation process.

### 2. Innovative points
The main innovation of the method is that it combines data-driven and geometry-driven techniques by using a 2D diffusion network to act as a generic data-driven regulariser to improve video-specific 3D optimisation. This method can be applied not only to hand-object interaction scenarios, but can also be generalised to other domains. 

### 3. Future Works
In future research, further exploration is needed to overcome these limitations and improve the accuracy. Also, the method can be combined with other techniques, such as deep learning, to better solve practical problems.    
