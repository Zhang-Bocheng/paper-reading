# TECA: Text-Guided Generation and Editing of Compositional 3D Avatars
[paper link](https://arxiv.org/pdf/2309.07125) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2023 | This paper describes a new method called TECA (Text-Guided Generation and Editing of Compositional 3D Avatars), which aims to create realistic 3D face avatars through textual descriptions and supports editing features.          |  Computer Vision        |

## Methodology

### 1. Abstract
Unlike existing methods, TECA employs a composite modelling approach where the head, face and upper body are represented as traditional 3D mesh models, while the hair, clothing and accessories are modelled using Neural Radiation Fields (NeRF). This approach improves realism and supports appearance modifications. In addition, TECA introduces a hierarchical approach to further optimise non-facial regions and has the ability to seamlessly transfer complex features such as hairstyles, scarves and other accessories. Experimental results show that TECA produces avatars that are more realistic than existing methods and easy to edit due to their composite nature.

### 2. Method Description 
The paper presents an algorithm called TECA for generating 3D face models from text descriptions. The algorithm uses the Stable Diffusion model to convert the text into an image and the SMPL-X model to fit the 3D face shape. Then, textures are generated by iterative interpolation technique (TEXTure) in different viewpoints. In addition, a NeRF model is used to generate other components such as hairstyles and clothing. Finally, a BLIP loss function is used to further optimise the details in RGB space.

![image](https://github.com/user-attachments/assets/1775c0a3-e73f-43b1-a75b-fd5d4a2c1d3b)

### 3. Methodological improvements
  1. 3D models can be generated directly from textual descriptions without the need for manual drawing or scanning.
 
  2. Uses a variety of techniques (e.g., SMPL-X, NeRF, and CLIPSeg) to make the generated models more realistic and detailed.
  
  3. Combines iterative interpolation techniques and colour similarity loss to improve the representation of details.

### 4. Issues addressed 
  1. Accurately capture a character's external features based on textual descriptions.
  
  2. Generate realistic 3D facial geometry and textures.
 
  3. Ability to generate non-facial elements such as hair, clothing and other accessories.

## Experiments
This paper focuses on a number of sets of experiments conducted by the authors using the TECA methodology, which are analysed and compared in detail. Specifically, the paper includes the following five aspects of experiments:

**Comparison experiments with SOTA methods**: the authors compared TECA with four other SOTA methods (SJC, Latent-NeRF, Latent-Paint, and TEXTure) in order to evaluate its capability in generating diverse constructed avatars. By comparing the avatars generated by the different methods, the authors found that TECA is visually more realistic and natural with stronger cross-view consistency.

**Online Perceptual Experiment**: The authors conducted an online perceptual experiment in which participants were invited to rate the avatars generated by TECA and the other four methods. By counting and analysing participants' comments, the authors concluded that TECA received higher ratings for both visual realism and consistency of textual descriptions.

**Quantitative Evaluation Experiment**: the authors also conducted a quantitative evaluation of TECA, using CLIP scores and FID to measure the quality of the avatars. The results show that TECA excels in both text description matching and image quality.

![image](https://github.com/user-attachments/assets/fd73c13c-2d86-44b3-bd0a-6dd4efdbbab0)

**Application Experiments**: since TECA is constructive, non-facial components such as hairstyles and accessories can be applied to different avatars. In addition, the authors also implemented the animation function of avatars using the SMPL-X model, demonstrating the dynamic effects of avatars in various poses and expressions.

![image](https://github.com/user-attachments/assets/81466105-4efc-41f6-a940-2667cb945702)

**Model Design Choice Experiments**: The authors conducted two sets of Ablation experiments to explore the effects of non-facial detail refinement and CLIPSeg segmentation loss on avatar generation. The results show that refining non-facial details significantly improves the overall visual quality, while CLIPSeg segmentation loss helps to prevent NeRF from attempting to represent the entire avatar, thus focusing on the representation of specific parts. 

![image](https://github.com/user-attachments/assets/47e06bf4-bc31-4b06-a45e-e20a0e681688)

## Conclusion

### 1. Advantages of the Thesis
By using different representations to distinguish different components, the authors successfully address the limitations of existing methods in terms of realism, shape fidelity and editing capabilities. Experimental results show that TECA performs better relative to state-of-the-art methods, generating highly detailed editable avatars and enabling transfer between hairstyles and accessories. In addition, the method supports relighting across environments.

### 2. Innovative points
   1. **Different representations were used to differentiate between the different components**: by dividing the avatar into two main parts, the face/body and the non-face/body regions, as well as by using the SMPL-X body model to represent the shapes of the head and shoulders, the authors succeeded in resolving the differences in geometric and cosmetic attributes that existed between the different components.
 
   2. **The benefits of Neural Radiation Fields (NeRF) were exploited**: by applying NeRF to the modelling of non-face components such as hair, clothing, etc., these components were able to better reflect the diversity geometry and reflectivity, thus improving the realism of the generated avatars.
 
   3. **CLIPSeg is employed for segmentation guidance**: by using CLIPSeg to obtain masks for regions of interest (e.g., hair or clothing), NeRF is prompted to focus on learning specific components rather than the entire avatar, which helps to improve the quality of the avatar.
      
### 3. Future Works
  1. **Dynamic processing**: while TECA has demonstrated capabilities in dynamic elements (e.g., hair and clothing), further exploration of how to handle complex dynamic effects more efficiently is a potential research direction.
  
  2. **Re-illumination**: due to the learning of RGB colours with facial textures and NeRF-based 
