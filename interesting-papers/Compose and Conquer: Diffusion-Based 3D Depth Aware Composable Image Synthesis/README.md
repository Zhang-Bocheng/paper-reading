# Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis
[paper link](https://arxiv.org/pdf/2401.09048) 
| Year | Introduction                                                         | Research Field                 |
| ---- | ------------------------------------------------------------ | -------------------- |
| 2024 | This thesis describes a diffusion model-based image synthesis method designed to address the limitations that exist when text is used as a source of accurate layout representations and to enable control over the position and style of objects in three-dimensional space.          |  Diffusion  & Deep Learning      |

## Methodology

### 1. Abstract
The method uses depth-separation training to estimate the relative depths between objects, and synthesises image triples to identify the absolute positions of unseen objects. In addition, the method introduces a soft steering technique that allows global semantics to be applied to the target region without additional localisation cues. The final proposed framework ‘COMPOSE AND CONQUER’ (CNC) integrates these techniques and enables decentralised processing of multiple conditions. Experimental results show that the method can perceive objects at different depths and provides a flexible framework for combining local objects with different global semantics.

### 2. Method Description 
The ‘Compose and Conquer’ (CnC) method proposed in this paper is a deep learning based image synthesis technique whose goal is to generate realistic images based on given conditions. The method consists of two main components: **a local fuser and a global fuser**. The local fuser extracts the depth information using a pre-trained depth estimation network and combines it with a pre-trained textual conditional diffusion model. The global fuser, on the other hand, uses CLIP image embedding to provide global semantic information for specific regions.

![image](https://github.com/user-attachments/assets/353957ea-c3a2-407f-8b38-9caaee4f0c5d)

### 3. Methodological improvements
In the local fuser, CnC employs both depth map generation and depth disentanglement training (DDT). First, training samples with objects placed at different depths are generated by synthesising image triples; these samples are then used for depth disentanglement training to distinguish each representation and learn depth relationships. This approach allows the model to efficiently identify elements behind occluders, leading to a better understanding of relative depth positions.

In the global fuser, CnC employs a soft bootstrapping approach to localisation by adding a binary mask to the cross-attention layer. This approach allows the model to maintain attention to textual conditions while reflecting global semantic information.

![image](https://github.com/user-attachments/assets/1582d694-1e7c-465d-aacf-10ebf32c0d57)

### 4. Issues addressed 
How to capture the relative depth relationships between objects.
How to provide global semantic information for specific regions.
How to make the generated image more textually conditional without sacrificing global semantics.

In conclusion, the CnC method achieves high-quality, realistic and text-conditionally-compliant image synthesis by combining depth information and global semantics, as well as applying deep decoupling training and soft bootstrapping methods.

## Experiments
This paper focuses on a method for generating images using depth images and CLIP image embedding as conditions and compares it with other methods. Specifically, the method generates an image by dividing the depth image into two parts, foreground and background, and adding different semantic information to each of the two parts. In addition, the method utilises CLIP image embedding to add global semantic information. The experimental results in this paper show that the method has better performance compared to other methods, especially in the balance between structural and semantic information.

Firstly, this paper compares different models quantitatively and qualitatively. The quantitative evaluation metrics include FID, Inception Score and CLIP Score, etc., while the qualitative evaluation adopts manual observation. The experimental results show that the method scores slightly lower than other methods in terms of FID and Inception Score, but higher than other methods in terms of CLIP Score. In addition, in terms of qualitative evaluation, the images generated by this method can better reflect the balanced relationship between semantic and structural information.

![image](https://github.com/user-attachments/assets/38a69898-eaab-40b8-ab63-6dd8511aa31e)

Secondly, reconstruction experiments are also conducted in this paper to verify whether the method can accurately restore the original image while maintaining the structural and semantic information of the image. The experimental results show that the method is able to faithfully reproduce the position and depth information of the object while maintaining the structural and semantic information of the image, which is a better performance compared to other methods.

Finally, ablation experiments are also conducted in this paper to verify the effectiveness of the soft guidance mechanism. The experimental results show that the soft bootstrapping mechanism can effectively prevent the concept leakage phenomenon from occurring, and at the same time ensure that the semantic information in the local region will not be covered by the global semantic information.  

![image](https://github.com/user-attachments/assets/0c1bdd4b-2e1f-419b-9ecd-3d5494835eb2)

## Conclusion

### 1. Advantages of the Thesis
  1. The model employs two main components: a local fuser and a global fuser to achieve these goals using depth-dissociation training (DDT) and soft bootstrapping techniques, respectively.
  2. The authors show experimentally that CnC performs well in handling the 3D location of multiple objects and injecting global semantics into specific regions, and has higher accuracy and stability relative to other benchmark models.

### 2. Innovative points
  1. **Depth Separation Training (DDT):** this is a new training paradigm that helps the model to understand the relative 3D spatial positional relationships between multiple objects.DDT feeds the local fuser by extracting depth maps from synthetic image triples.
  2. **Soft bootstrapping:** this is a technique for localising global conditions to inject global semantics into specific regions without explicit structural cues. Soft bootstrapping achieves this by selectively masking specific regions in the attention matrix. 

### 3. Future Works
  1. The current framework limits the number of available conditions and the decomposition of foreground and background, thus further research is needed on how to decompose an image into depth depicting elements and intermediate zones. 
  2. CnC is still limited to generating objects in the 2D plane, and thus needs to explore how to better deal with object placement in the 3D or z-axis (depth) perspective.
  3. CnC can also be considered in combination with other techniques such as multimodal learning and reinforcement learning to improve its performance and adaptability.    
